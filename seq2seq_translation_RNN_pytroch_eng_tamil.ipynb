{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP From Scratch: Translation with a Sequence to Sequence Network\n",
    "===============================================================================\n",
    "##### originally written by: Sean Robertson\n",
    "##### modified by: Vinothkumar\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ref: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "##### modified to English to Tamil translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[.!?]+\", r\" \", s) #modifiled for tamil letters\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "\n",
    "    #Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 20\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "# def filterPair(p):\n",
    "#     return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "#         len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "#         p[1].startswith(eng_prefixes)\n",
    "    \n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 392 sentence pairs\n",
      "Trimmed to 389 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 645\n",
      "tamil 920\n",
      "['she sat next to me', 'அவள எனககு அருகில அமரநதாள']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=True):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    #commented (filter pair did not work for tamil)\n",
    "    pairs = filterPairs(pairs)\n",
    "    \n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'tamil', False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i love you', 'நான உனனை காதலிககிறேன'],\n",
       " ['where are you', 'ந எஙகே இருககிறாய'],\n",
       " ['where are you going', 'நஙகள எஙகே போகிறரகள'],\n",
       " ['i have to go to the toilet', 'நான கழிவறைககுச செலல வேணடும'],\n",
       " ['\"i like the movie \"\"me\"\"  \"', 'நான எனறு படம விருமபுகிறேன'],\n",
       " ['something extraordinary happened to me this morning',\n",
       "  'ஒரு விசிததிரமான ஒனறு இனறு காலை எனககு நடநதது'],\n",
       " ['would you like to improve your english',\n",
       "  'உஙகள ஆஙகிலம மேமபடுதத வேணடுமென விருமபுகிறரகளா'],\n",
       " ['i tried to understand what had happened',\n",
       "  'எனன நடநதது எனபதை தெரிநது கொளள விருமபினேன'],\n",
       " ['tom tried not to cry', 'டோம அழாமல இருகக முயனறான'],\n",
       " [\"where's tom been all day\", 'நாள முழுதும டோம எஙகிருநதான']]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "    input_lang, output_lang, pairs = prepareData('eng', 'tamil', False)\n",
    "\n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(target_ids).to(device))\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    return input_lang, output_lang, train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, _ = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=100):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 392 sentence pairs\n",
      "Trimmed to 389 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 645\n",
      "tamil 920\n",
      "0m 1s (- 0m 26s) (5 5%) 2.3450\n",
      "0m 2s (- 0m 24s) (10 10%) 1.3701\n",
      "0m 4s (- 0m 23s) (15 15%) 1.2589\n",
      "0m 5s (- 0m 21s) (20 20%) 1.1443\n",
      "0m 6s (- 0m 19s) (25 25%) 1.0151\n",
      "0m 7s (- 0m 18s) (30 30%) 0.8749\n",
      "0m 9s (- 0m 17s) (35 35%) 0.7412\n",
      "0m 10s (- 0m 15s) (40 40%) 0.6060\n",
      "0m 11s (- 0m 14s) (45 45%) 0.4875\n",
      "0m 13s (- 0m 13s) (50 50%) 0.3925\n",
      "0m 14s (- 0m 11s) (55 55%) 0.3155\n",
      "0m 15s (- 0m 10s) (60 60%) 0.2571\n",
      "0m 16s (- 0m 9s) (65 65%) 0.2177\n",
      "0m 18s (- 0m 7s) (70 70%) 0.1877\n",
      "0m 19s (- 0m 6s) (75 75%) 0.1630\n",
      "0m 20s (- 0m 5s) (80 80%) 0.1422\n",
      "0m 22s (- 0m 3s) (85 85%) 0.1245\n",
      "0m 23s (- 0m 2s) (90 90%) 0.1094\n",
      "0m 24s (- 0m 1s) (95 95%) 0.0966\n",
      "0m 25s (- 0m 0s) (100 100%) 0.0850\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 16\n",
    "\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "train(train_dataloader, encoder, decoder, 100, print_every=5, plot_every=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set dropout layers to `eval` mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> i like orange\n",
      "= எனககு ஆரஞசு பிடிககும\n",
      "< எனககு சிவபபு <EOS>\n",
      "\n",
      "> raise your hand\n",
      "= கையைத தூககு\n",
      "< கையைத <EOS>\n",
      "\n",
      "> i'm getting old\n",
      "= வயசு ஆகது\n",
      "< வயசு <EOS>\n",
      "\n",
      "> i'll walk\n",
      "= நான நடபபேன\n",
      "< நான தூஙகுகிறேன <EOS>\n",
      "\n",
      "> rain is like ambrosia, as the world cannot exist without rain\n",
      "= வானின றுலகம வழஙகி வருதலால தானமிழதம எனறுணரற பாறறு\n",
      "< பூசனை வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> when he spoke, everyone became silent\n",
      "= அவன பேசியப பொழுது எலலோரும அமைதி காததாரகள\n",
      "< வேணடுதல வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> it needs help right now\n",
      "= அதறகு இபபோது உதவி தேவை\n",
      "< சிறபபொடு ஒழுகக நெறிநினறார நடுவாழ வார <EOS>\n",
      "\n",
      "> do you have a lot of pens\n",
      "= உனனிடம நிறைய பேனாககள இருககினறனவா\n",
      "< நஙகள கணிசமான சமபளம தர வேணடும <EOS>\n",
      "\n",
      "> would you like to improve your english\n",
      "= உஙகள ஆஙகிலம மேமபடுதத வேணடுமென விருமபுகிறரகளா\n",
      "< சிறபபொடு பூசனை செலலாது வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> i'll leave that to you\n",
      "= நான அதை உனனிடம விடடு விடுகிறேன\n",
      "< நான தூஙகவிலலை  \" <EOS>\n",
      "\n",
      "> eat slowly\n",
      "= மெதுவாக சாபபிடுஙகள\n",
      "< ந நினைககிறாய <EOS>\n",
      "\n",
      "> tom has been unconscious for three days\n",
      "= டோம மூனறு நாடகளாக நினைவிழநது இருககிறான\n",
      "< சிறபபொடு பூசனை வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> he has three sons\n",
      "= அவருககு மூனறு மகனகள\n",
      "< விணஇனறு வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> he's getting old\n",
      "= வயசு ஆகது\n",
      "< வயசு ஆகது <EOS>\n",
      "\n",
      "> she asked him for some money\n",
      "= அவனைக கொஞசம பணம கேடடாள\n",
      "< உஙகளுடைய வேலையாடகள <EOS>\n",
      "\n",
      "> i want to be a pilot in the future\n",
      "= நான எதிர காலததில ஒரு விமானியாக விருமபுகிறேன\n",
      "< \"ந தூஙகவிலலை  \" <EOS>\n",
      "\n",
      "> i slept\n",
      "= நான தூஙகினேன\n",
      "< நான கணடுபிடிததேன <EOS>\n",
      "\n",
      "> my throat hurts when i swallow\n",
      "= சினன கேககுத துணடு அவள தொணடையில சிககிக கொணடது\n",
      "< சிறபபொடு பூசனை வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> if you want your workers to be happy, you need to pay them a decent wage\n",
      "= உஙகளுடைய வேலையாடகள மகிழசசியாக இருகக வேணடுமெனறால நஙகள கணிசமான சமபளம தர வேணடும\n",
      "< சிறபபொடு பூசனை வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> they're about to leave\n",
      "= அவரகள கிளமப இருககிறாரகள\n",
      "< பொறிவாயில ஐநதவிததான கடடிடததை ஆகிறது <EOS>\n",
      "\n",
      "> why did you leave\n",
      "= ந ஏன போனாய\n",
      "< \"ந நடுவாழ வார <EOS>\n",
      "\n",
      "> all of us were silent\n",
      "= நாஙகள அனைவரும அமைதியாக இருநதோம\n",
      "< ஒருவர பயன படுததுவதைக கேடடு ரொமப <EOS>\n",
      "\n",
      "> we all cried when we watched the movie\n",
      "= அததிரைபபடததைப பாரததபோது நாஙகள அனைவரும அழுதோம\n",
      "< வேணடுதல வேணடாமை இலானடி <EOS>\n",
      "\n",
      "> do you know when he will come\n",
      "= அவன எபப வருவான எனறு உனககுத தெரியுமா\n",
      "< வேணடுதல <EOS>\n",
      "\n",
      "> i will come back tomorrow\n",
      "= நான நாளைககு வரேன\n",
      "< நான தூஙகவிலலை  \"\" \"\"எனககுத தூககம <EOS>\n",
      "\n",
      "> climate change causes sea levels to rise\n",
      "= கடல மடடம உயரவதறகு தடபவெபப மாறறம காரணமாக இருககிறது\n",
      "< சிறபபொடு பூசனை வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> tom goes to church with mary every sunday\n",
      "= டாம மேரியுடன ஒவவொரு ஞாயிறறுக கிழமையும தேவாலயததுககுச செலகிறான\n",
      "< \"ந நடுவாழ வார <EOS>\n",
      "\n",
      "> i didn't tell them\n",
      "= நான அவரகளிடம சொலலவிலலை\n",
      "< நான அவரகளிடம <EOS>\n",
      "\n",
      "> when did you come to japan\n",
      "= ந எபபொழுது ஜபபான வநதாய\n",
      "< பொறிவாயில ஐநதவிததான பொயதர ஈணடு <EOS>\n",
      "\n",
      "> what is the time\n",
      "= மணி எனன ஆகிறது\n",
      "< மணி <EOS>\n",
      "\n",
      "> what do you plan to do\n",
      "= ந எனன செயயத திடடமிடடிருககிறாய\n",
      "< ந ஆஙகிலம நடுவாழ வார <EOS>\n",
      "\n",
      "> the cat is hiding\n",
      "= பூனை மறைகிறது\n",
      "< பூனை <EOS>\n",
      "\n",
      "> speak slowly and clearly\n",
      "= மெதுவாகவும தெளிவாகவும பேசுஙகள\n",
      "< மெதுவாகவும தெளிவாகவும இருகக <EOS>\n",
      "\n",
      "> i'm getting old\n",
      "= வயசு ஆகது\n",
      "< வயசு <EOS>\n",
      "\n",
      "> he's getting old\n",
      "= வயசு ஆகது\n",
      "< வயசு ஆகது <EOS>\n",
      "\n",
      "> when should we leave\n",
      "= எபபோ கிளமபலாம\n",
      "< என ஐநதவிததான பொயதர ஈணடு <EOS>\n",
      "\n",
      "> go to sleep\n",
      "= போய தூஙகு\n",
      "< எனனிடம சொனனான <EOS>\n",
      "\n",
      "> if you have faith in god, you can control all five senses and live a peaceful, long life\n",
      "= பொறிவாயில ஐநதவிததான பொயதர ஒழுகக நெறிநினறார நடுவாழ வார\n",
      "< பொறிவாயில ஐநதவிததான பொயதர ஒழுகக நெறிநினறார நடுவாழ <EOS>\n",
      "\n",
      "> he put the ring on mary's finger\n",
      "= அவன மேரியின விரலில மோதிரததை அணிவிததான\n",
      "< வேணடுதல வறககுமேல வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> please sit here and wait\n",
      "= இஙகே அமருஙகள,தயவு செயது காததிருஙகள\n",
      "< வேணடுதல வேணடாமை <EOS>\n",
      "\n",
      "> he is afraid of snakes\n",
      "= அவரகளுககு பாமபுகள எனறால பயம\n",
      "< சிறபபொடு பூசனை வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> she kissed her baby\n",
      "= அவள குழநதையை முததமிடடாள\n",
      "< அவள நெறிநினறார நடுவாழ வார <EOS>\n",
      "\n",
      "> friendship requires mutual trust\n",
      "= நடபுககுத தேவை பரஸபர நமபிககை\n",
      "< பொறிவாயில ஐநதவிததான பொயதர ஈணடு <EOS>\n",
      "\n",
      "> what's the time\n",
      "= மணி எனன ஆகிறது\n",
      "< மணி <EOS>\n",
      "\n",
      "> where's tom been all day\n",
      "= நாள முழுதும டோம எஙகிருநதான\n",
      "< சிறபபொடு பூசனை வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> those are my cds\n",
      "= அவைகள எனனுடைய cd கள\n",
      "< சிறபபொடு பூசனை செலலாது பசி <EOS>\n",
      "\n",
      "> punch her\n",
      "= அவளை குதது\n",
      "< அவளை <EOS>\n",
      "\n",
      "> climate change causes sea levels to rise\n",
      "= கடல மடடம உயரவதறகு தடபவெபப மாறறம காரணமாக இருககிறது\n",
      "< சிறபபொடு பூசனை வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> i think it'll rain tonight\n",
      "= இனறு இரவு மழை பெயயும எனறு நினைககிறேன\n",
      "< வேணடுதல வேணடாமை இலானடி சேரநதாரககு யாணடும <EOS>\n",
      "\n",
      "> give it to her\n",
      "= அவளிடம கொடு\n",
      "< அவள இருககிறது <EOS>\n",
      "\n",
      "> she is not afraid of anything\n",
      "= அவள எதறகும பயபபடுவதிலலை\n",
      "< அவள எபபொழுதும பாறறு <EOS>\n",
      "\n",
      "> rain is like ambrosia, as the world cannot exist without rain\n",
      "= வானின றுலகம வழஙகி வருதலால தானமிழதம எனறுணரற பாறறு\n",
      "< பூசனை வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> friendship requires mutual trust\n",
      "= நடபுககுத தேவை பரஸபர நமபிககை\n",
      "< பொறிவாயில ஐநதவிததான பொயதர ஈணடு <EOS>\n",
      "\n",
      "> punch her\n",
      "= அவளை குதது\n",
      "< அவளை <EOS>\n",
      "\n",
      "> they're about to leave\n",
      "= அவரகள கிளமப இருககிறாரகள\n",
      "< பொறிவாயில ஐநதவிததான கடடிடததை ஆகிறது <EOS>\n",
      "\n",
      "> can you ride a bicycle\n",
      "= உஙகளுககு சைககிள ஓடடத தெரியுமா\n",
      "< \"ந தூஙகவிலலை நெறிநினறார நடுவாழ வார <EOS>\n",
      "\n",
      "> the zionist project goes back to the late 19th century\n",
      "= சியோனிஸட திடடம 19ஆம நூறறாணடின பிறபகுதியிலேயே ஆரமபிததுவிடடது\n",
      "< சிறபபொடு பூசனை வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> he has three sons\n",
      "= அவருககு மூனறு மகனகள\n",
      "< விணஇனறு வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> you are being guided\n",
      "= ந வழி காடடப படடுக கொணடு இருககிறாய\n",
      "< \"ந <EOS>\n",
      "\n",
      "> tom has finally done what we asked him to do\n",
      "= டோம இறுதியாக நாம அவனிடம கேடடதைச செயது முடிததான\n",
      "< சிறபபொடு பூசனை வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> he came back soon\n",
      "= அவன சககிரம திருமபி வநதான\n",
      "< உளநின றுடறறும பசி <EOS>\n",
      "\n",
      "> fire   run\n",
      "= த   ஓடுஙகள\n",
      "< வேணடுதல வறககுமேல வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> i can't find it anywhere\n",
      "= இது எஙகே இருககு எனறு எனனால கணடுபிடிகக முடியவிலலை\n",
      "< \"ந தூஙகவிலலை  \"\" \"\"எனககுத தூககம வராததால நான தூஙகவிலலை <EOS>\n",
      "\n",
      "> you are leading the way\n",
      "= ந வழி காடடப படுகிறாய\n",
      "< ந நினைககிறாய <EOS>\n",
      "\n",
      "> she decided to go\n",
      "= அவள போகத தரமானிததாள\n",
      "< அவள எபபொழுதும இருநததிலலை <EOS>\n",
      "\n",
      "> three vicious dogs attacked tom\n",
      "= மூனறு மோசமான நாயகள டாமை தாககின\n",
      "< சிறபபொடு பூசனை வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> he came back soon\n",
      "= அவன சககிரம திருமபி வநதான\n",
      "< உளநின றுடறறும பசி <EOS>\n",
      "\n",
      "> don't think about it   do it\n",
      "= அதைபபறறி எணணிககொணடிருககாதே   செயலபடு\n",
      "< சிறபபொடு பூசனை வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> i just want you to come\n",
      "= ந வர வேணடுமென விருமபுகிறேன\n",
      "< ந நினைககிறாய செயவேன <EOS>\n",
      "\n",
      "> i am him\n",
      "= நான அவன\n",
      "< நான அறிநதிருககவிலலை <EOS>\n",
      "\n",
      "> she boiled the eggs\n",
      "= அவள முடடைகளை வேக வைததாள\n",
      "< அவள எபபொழுதும நடுவாழ வார <EOS>\n",
      "\n",
      "> if rain fails, farmers will stop ploughing\n",
      "= ஏரின உழாஅர உழவர புயலஎனனும வாரி வளஙகுனறிக கால\n",
      "< வேணடுதல வறககுமேல வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> he has three sons\n",
      "= அவருககு மூனறு மகனகள\n",
      "< விணஇனறு வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> everyone hurried outside\n",
      "= அனைவரும அவசரமாக வெளியேறினர\n",
      "< அனைவரும சமபளம தர வேணடும <EOS>\n",
      "\n",
      "> i know what to do\n",
      "= எனன செயவது எனபது எனககுத தெரியும\n",
      "< எனன செயய வேணடும <EOS>\n",
      "\n",
      "> it's the third biggest city in serbia\n",
      "= இது செரபியாவின மூனறாவது பெரிய நகரம\n",
      "< சிறபபொடு பூசனை செலலாது வறககுமேல வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> he was not aware of the danger\n",
      "= அவன அபாயததை அறிநதிருகக விலலை\n",
      "< என இடுமபை இல <EOS>\n",
      "\n",
      "> everyone ran outside\n",
      "= அனைவரும வெளியே ஓடினர\n",
      "< ஒருவர பயன படுததுவதைக கேடடு <EOS>\n",
      "\n",
      "> they come from many countries\n",
      "= அவரகள பல நாடுகளில இருநது வருகிறாரகள\n",
      "< சிறபபொடு பூசனை செலலாது வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> you are being guided\n",
      "= ந வழி காடடப படடுக கொணடு இருககிறாய\n",
      "< \"ந <EOS>\n",
      "\n",
      "> i'm not sure how to answer this\n",
      "= எபபடி பதில சொலவது எனபதில நான உறுதியாக இலலை\n",
      "< \"ந நடுவாழ வார <EOS>\n",
      "\n",
      "> i'll walk\n",
      "= நான நடபபேன\n",
      "< நான தூஙகுகிறேன <EOS>\n",
      "\n",
      "> we'll follow you\n",
      "= நாஙகள உனனைத பினபறறுவோம (அ) தொடரவோம\n",
      "< மலரமிசை ஏகினான மாணடி சமபளம தர வேணடும <EOS>\n",
      "\n",
      "> i can't find it anywhere\n",
      "= இது எஙகே இருககு எனறு எனனால கணடுபிடிகக முடியவிலலை\n",
      "< \"ந தூஙகவிலலை  \"\" \"\"எனககுத தூககம வராததால நான தூஙகவிலலை <EOS>\n",
      "\n",
      "> i will come back tomorrow\n",
      "= நான நாளைககு வரேன\n",
      "< நான தூஙகவிலலை  \"\" \"\"எனககுத தூககம <EOS>\n",
      "\n",
      "> she has never been in a car driven by him\n",
      "= அவன ஒடடினக காரில அவள எபபொழுதும இருநததிலலை\n",
      "< வேணடுதல வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> i expect him to come\n",
      "= அவன வருவான என எதிர பாரககிறேன\n",
      "< வேணடுதல வறககுமேல <EOS>\n",
      "\n",
      "> please help\n",
      "= உதவி செய\n",
      "< SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS\n",
      "\n",
      "> i knew that would happen\n",
      "= அது நடககும எனறு எனககுத தெரியும\n",
      "< பசி <EOS>\n",
      "\n",
      "> what is the use of learning if you don't worship god or respect learned persons\n",
      "= கறறதனால ஆய பயனெனகொல வாலறிவன நறறாள தொழாஅர எனின\n",
      "< சிறபபொடு பூசனை செலலாது வானம வறககுமேல <EOS>\n",
      "\n",
      "> i like purple\n",
      "= எனககு ஊதா பிடிககும\n",
      "< எனககு அவவளவு தெரியும <EOS>\n",
      "\n",
      "> i arrived ahead of the others\n",
      "= மறறவரகளுககு முனனே நான வநதேன\n",
      "< \"ந நடுவாழ வார <EOS>\n",
      "\n",
      "> do you have a lot of pens\n",
      "= உனனிடம நிறைய பேனாககள இருககினறனவா\n",
      "< நஙகள கணிசமான சமபளம தர வேணடும <EOS>\n",
      "\n",
      "> be kind to old people\n",
      "= வயோதிகரகளிடம அனபாக இரு\n",
      "< விணஇனறு வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> fire   run\n",
      "= த   ஓடுஙகள\n",
      "< வேணடுதல வறககுமேல வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> he is known to everyone\n",
      "= அவன ஒவவொருவருககும அறிமுகமானவன\n",
      "< அவன <EOS>\n",
      "\n",
      "> when did the wedding take place\n",
      "= கலயாணம எபபொழுது நடைப பெறறது\n",
      "< பூசனை செலலாது வானோரககும ஈணடு <EOS>\n",
      "\n",
      "> i am her\n",
      "= நான அவள\n",
      "< நான அறிநதிருககவிலலை <EOS>\n",
      "\n",
      "> she danced with him\n",
      "= அவள அவனோடு நடனம ஆடினாள\n",
      "< அவள எபபொழுதும இருநததிலலை <EOS>\n",
      "\n",
      "> don't lie to me\n",
      "= எனனிடம பொய சொலலாதே\n",
      "< எனனிடம சொனனான <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
